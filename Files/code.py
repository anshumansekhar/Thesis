# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OrpsBWzWH7-ZG7VH6-Jb7FgJu8WUNAZL
"""

import pandas as pd
import numpy as np
import nltk
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import StandardScaler, normalize
from sklearn.metrics import silhouette_score
import scipy.cluster.hierarchy as shc

data = pd.read_csv('/content/components.csv')
min_data=data.drop(['id','Component Name','Functionality'],axis=1)
min_data.fillna(method='ffill',inplace=True)
min_data.head()

!pip install Levenshtein

import Levenshtein
similarity=np.zeros( (len(min_data), len(min_data)) )
for i in range(len(min_data)):
  for j in range(len(min_data)):
    if i==j:
      similarity[i][j]=0
    else:
      min_data["uniqueText"] = min_data["Language"] + min_data["Type"]+min_data["Domain"]+min_data["Visibility"]
      similarity[i][j]=Levenshtein.ratio(min_data.iloc[i]["uniqueText"], min_data.iloc[j]["uniqueText"])

similarity

model = AgglomerativeClustering(affinity='precomputed', n_clusters=39, linkage='complete').fit(similarity)
print(model.labels_)

print("Enter query for component search")

query="A java component for railway reservation containing login using username and password with captcha functionality , date picker , dropdown for cities , train class and quota , calculation of fare using Calculate Button with distance , train class and quota , dedicated payment page with options like debit card , credit card , upi , page to display list of trains "

from nltk.tokenize import word_tokenize
nltk.download('punkt')
keywords=word_tokenize(query)

from nltk.corpus import stopwords
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))
len(stop_words)

keywords_min=set()
for word in keywords:
    if word.lower() not in stop_words:
        keywords_min.add(word)
print(keywords_min)

similarityScores=[]

for index, row in data.iterrows():
  matched_words=0.0
  string=row['Functionality'].split(' ')
  for word1 in string:
    for word in keywords:
      if word==word1:
        matched_words=matched_words+1;
  score=matched_words/len(row['Functionality'])
  similarityScores.append(score)

similarityScores
data['similarityScore'] = similarityScores
data=data.sort_values(by=['similarityScore'],ascending=False)
data=data.drop(['id','Domain','Visibility','Type'],axis=1)
data